# Context-Text-Classifier: Klasyfikator Pyta≈Ñ Konwergentnych

Projekt **Context-Text-Classifier** to dwuklasowy klasyfikator sekwencji oparty na modelu **HerBERT-base-cased**, kt√≥rego celem jest automatyczne rozr√≥≈ºnianie, czy zadane pytanie w jƒôzyku polskim wymaga jednoznacznego faktu (np. liczby, daty, nazwy), czy te≈º szerszego kontekstu lub opinii.

Model zosta≈Ç wytrenowany i zoptymalizowany przy u≈ºyciu **Optuna Hyperparameter Optimization**, osiƒÖgajƒÖc **wysoki wynik F1 (95.9%)** dziƒôki technikom r√≥wnowa≈ºenia klas oraz ≈õwiadomemu przygotowaniu zbioru danych.

---

## Definicja problemu

Celem projektu jest **automatyczna klasyfikacja pyta≈Ñ** w jƒôzyku polskim, np. dla zastosowa≈Ñ w systemach **Question Answering (QA)** lub **Chatbotach**.

| Klasa | Nazwa | Opis | Przyk≈Çad |
|:---:|---|---|---|
| **1** | Konwergentne / Fakt | Pytanie jednoznaczne, z jednƒÖ mo≈ºliwƒÖ odpowiedziƒÖ (fakt, liczba, nazwa, data). | ‚ÄûIle serc ma o≈õmiornica?‚Äù |
| **0** | Dywersyjne / Brak faktu | Pytanie niepe≈Çne, subiektywne, zbyt og√≥lne lub wymagajƒÖce opisu. | ‚ÄûIle?‚Äù |

---

## Wyniki i metryki

Model zosta≈Ç wytrenowany przy u≈ºyciu **Optuny (HPO)** oraz **wa≈ºonej funkcji strat (Weighted Cross-Entropy Loss)**.  
Najlepszy wynik osiƒÖgniƒôto po **4 epokach** treningu ‚Äî model uzyska≈Ç bardzo wysokie i zr√≥wnowa≈ºone wyniki pod wzglƒôdem precyzji (Precision) i czu≈Ço≈õci (Recall).

| Epoka | Training Loss | Validation Loss | Accuracy | F1 (Weighted) | Precision | Recall | F1 Klasy 0 (Dywersyjne) | F1 Klasy 1 (Fakt) |
|:------:|:--------------:|:----------------:|:---------:|:--------------:|:----------:|:--------:|:----------------------:|:----------------:|
| 1 | ‚Äì | 0.2796 | 0.9456 | 0.9452 | 0.9477 | 0.9456 | 0.9531 | 0.9352 |
| 2 | 0.2150 | 0.2630 | 0.9541 | 0.9539 | 0.9553 | 0.9541 | 0.9601 | 0.9459 |
| 3 | 0.2150 | 0.2313 | 0.9575 | 0.9574 | 0.9578 | 0.9575 | 0.9626 | 0.9507 |
| **4** | **0.0710** | **0.2935** | **0.9592** | **0.9590** | **0.9600** | **0.9592** | **0.9644** | **0.9522** |

‚û°Ô∏è **Najlepszy model**: *Epoka 4*  
üìà **Weighted F1 = 0.9590**, **Precision = 0.9600**, **Recall = 0.9592**


---

## Technologie i metody

- **Model bazowy:** [`allegro/herbert-base-cased`](https://huggingface.co/allegro/herbert-base-cased)
- **Framework:** Hugging Face Transformers + PyTorch  
- **Optymalizacja:** [Optuna](https://optuna.org/) (Hyperparameter Search)
- **Metryki:** Accuracy, Weighted F1, Precision, Recall  
- **Dataset:** autorski zbi√≥r pyta≈Ñ sklasyfikowanych jako faktowe / niefaktowe  
- **Tokenizacja:** AutoTokenizer z paddingiem i truncacjƒÖ do `max_length=128`

---

## Struktura repozytorium
```
context-text-classifier/
‚îú‚îÄ‚îÄ train_context_classifier.py # Fine-tuning modelu HerBERT z OptunƒÖ
‚îú‚îÄ‚îÄ context_predict.py # Skrypt do inferencji na nowych pytaniach
‚îú‚îÄ‚îÄ requirements.txt # Zale≈ºno≈õci Python
‚îî‚îÄ‚îÄ README.md # Dokumentacja projekt
```

---

## Uruchomienie projektu

### Klonowanie repozytorium

```
git clone https://github.com/<twoj_uzytkownik>/context-text-classifier.git
cd context-text-classifier
```
### Instalacja zale≈ºno≈õci
```
pip install -r requirements.txt

```

### Trening modelu
```
python train_context_classifier.py

```

### Predykcja
```
python context_predict.py

```

Przyk≈Çad interaktywnej sesji:
```
Context Classifier Demo (type 'exit' to quit)
Enter a question in Polish: Ile serc ma o≈õmiornica?
Predicted class: 1 | Probabilities: [0.04, 0.96]
```

## U≈ºyte techniki optymalizacji
- Optuna Hyperparameter Search
‚Üí automatyczny dob√≥r learning_rate, batch_size, num_train_epochs, weight_decay

- Early Stopping & Best Model Selection
‚Üí model z najwy≈ºszym f1 zapisany po treningu

- Weighted Loss Function
‚Üí r√≥wnowa≈ºy wp≈Çyw klas, zapobiegajƒÖc biasowi w danych

- Custom Metrics (per class F1)
‚Üí ocena skuteczno≈õci osobno dla ka≈ºdej klasy

## Wymagania systemowe

- Python 3.10+
- GPU (opcjonalnie, ale rekomendowane dla treningu)
- Pakiety (patrz requirements.txt):
```
torch>=2.0.0
transformers>=4.40.0
datasets>=2.18.0
optuna>=3.5.0
evaluate>=0.4.2
scikit-learn>=1.3.0
pandas>=2.1.0
numpy>=1.25.0
sacremoses
```

## Model na Hugging Face (opcjonalnie)
[![Hugging Face Model](https://img.shields.io/badge/HuggingFace-Model-yellow?logo=huggingface&logoColor=white)](https://huggingface.co/aleksannndra/context-text-classifier)
























